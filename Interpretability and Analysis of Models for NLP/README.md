## Interpretability and Analysis of Models for NLP

#### 2019

| Title | Summary | Paper Source |
| ----- | ------- | ----- |
Revealing the Dark Secrets of BERT | [Text Machine Blog](https://text-machine-lab.github.io/blog/2020/bert-secrets/) | [Paper](https://www.aclweb.org/anthology/D19-1445.pdf)
| Probing Neural Network Comprehension of Natural Language Arguments | [The Gradient](https://thegradient.pub/nlps-clever-hans-moment-has-arrived/) | [Paper](https://www.aclweb.org/anthology/P19-1459/)
| What Does BERT Look At? An Analysis of BERT's Attention | [dair.ai](https://medium.com/dair-ai/aspects-of-language-captured-by-bert-32bc3c54016f) | [Paper](https://arxiv.org/abs/1906.04341v1)
| Are Sixteen Heads Really Better than One? | [CMU ML Blog](https://blog.ml.cmu.edu/2020/03/20/are-sixteen-heads-really-better-than-one/?/) | [Paper](https://papers.nips.cc/paper/9551-are-sixteen-heads-really-better-than-one.pdf)

#### 2018

| Title | Summary | Paper Source |
| ----- | ------- | ----- |
| Olive Oil is Made of Olives, Baby Oil is Made for Babies: Interpreting Noun Compounds using Paraphrases in a Neural Model |  [dair.ai](https://medium.com/dair-ai/olive-oil-is-made-of-olives-baby-oil-is-made-for-babies-paper-summary-a6f9b5544761) |  [Paper](https://arxiv.org/abs/1803.08073)
